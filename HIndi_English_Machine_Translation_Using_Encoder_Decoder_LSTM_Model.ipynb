{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIndi-English Machine Translation Using Encoder  Decoder LSTM Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargavpirates/Machine-Language-Translation-/blob/master/HIndi_English_Machine_Translation_Using_Encoder_Decoder_LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtDLUhD3UDoV",
        "colab_type": "text"
      },
      "source": [
        "# HIndi-English Machine Translation Using Encoder  Decoder LSTM Model.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyGeu3yhlmI7",
        "colab_type": "text"
      },
      "source": [
        "1.  Here we have Hindi Sentence documents, we need to convert hindi sentence documents to english sentence documents .so, we need to design  Sequenc2Sequence model\n",
        "2.  Sequenc2Sequence models in deeplearning is RNN,LSTM,GRU\n",
        "\n",
        "### Most common Aarchitecture used to build Seq2Seq models is the Encoder Decoder architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zutxI146UKwv",
        "colab_type": "text"
      },
      "source": [
        "### mounting data from google Drive to Google Collab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B9EUl3AG1Au",
        "colab_type": "code",
        "outputId": "11fec2c7-2a7c-4341-fde2-3f427176e074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8v-pnQfG6j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/parallel/hindi.txt\" \"hindi.txt\"\n",
        "!cp \"/content/drive/My Drive/parallel/english.txt\" \"english.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwwh7m4JAR3g",
        "colab_type": "code",
        "outputId": "f14997d1-7f39-400f-c87e-a797f8523c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Sep  6 07:20:11 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V5k6pR8leXl",
        "colab_type": "text"
      },
      "source": [
        "### importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsin83eiHMYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9VOUyqHeUOL",
        "colab_type": "text"
      },
      "source": [
        "### Reading Text Data which is in .txt file and stoing them in a varible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-5SyAlbHN_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"hindi.txt\",encoding='utf-8') as f:\n",
        "    hindi_txt=f.read().split('\\n')\n",
        "with open(\"english.txt\",encoding='utf-8') as f:\n",
        "    english_txt=f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQA1PrJOeizx",
        "colab_type": "text"
      },
      "source": [
        "### Constructing DataFrame ontop of txt varibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i-ci754HQ3G",
        "colab_type": "code",
        "outputId": "0d5f1a01-a82f-4b4e-8fa5-06fe70f6d95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df= pd.DataFrame({\"hin\":hindi_txt,\"eng\":english_txt})\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1561841, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uhro5O_HYVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df=df[:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ub8sO9_fHbx",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtS5pjvoHeru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#covert all words in a documents to lower case\n",
        "df.hin=df.hin.apply(lambda x: x.lower())\n",
        "df.eng=df.eng.apply(lambda x: x.lower())\n",
        "df.hin=df.hin.apply(lambda x: re.sub(\"'\", '', x))\n",
        "df.eng=df.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "\n",
        "# Set of all special characters\n",
        "set_punc = set(string.punctuation\n",
        "# Remove all the special characters\n",
        "df.hin=df.hin.apply(lambda x: ''.join(ch for ch in x if ch not in set_punc))\n",
        "df.eng=df.eng.apply(lambda x: ''.join(ch for ch in x if ch not in set_punc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHHDtX_nAzs1",
        "colab_type": "code",
        "outputId": "349fa23f-babd-42bb-b411-9a4f9d236512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fEFTE3zi4AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# length of sentence must be greater then five\n",
        "indexNames = df[ (df['hin'].str.len()  <= 5) | (df['eng'].str.len()  <= 5) ].index\n",
        "df.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyfM5ewpksSV",
        "colab_type": "code",
        "outputId": "fae540fd-ce72-4523-9f19-50b694242e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88884, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKwVXo8Te5cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing Puncations in hindi txt\n",
        "from string import punctuation\n",
        "p = re.compile(r'[\\s{}]+'.format(re.escape(punctuation)))\n",
        "df.hin=df.hin.apply(lambda x: re.sub(p,' ', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHjRmhx1glQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all numbers from English text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df.eng=df.eng.apply(lambda x: x.translate(remove_digits))\n",
        "df.eng=df.eng.apply(lambda x: re.sub(\"[0-9]\", \"\", x))\n",
        "\n",
        "# Remove all numbers from Hindi text\n",
        "df.hin=df.hin.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "df.hin=df.hin.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))\n",
        "\n",
        "# Remove all English words from  Hindi text\n",
        "df.hin=df.hin.apply(lambda x: re.sub(\"[A-Za-z]\", \"\", x))\n",
        "\n",
        "df.hin=df.hin.apply(lambda x: x.strip())\n",
        "df.eng=df.eng.apply(lambda x: x.strip())\n",
        "df.hin=df.hin.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df.eng=df.eng.apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_drtt1Pgqef",
        "colab_type": "text"
      },
      "source": [
        "### Add [go] and [stop] tokens to target sequences\n",
        "   * [go] at the starting of sentence English  Sentence\n",
        "   * [Start] at the Ending of target English Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwNGSGqRgnCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add [go] and [stop] tokens to target sequences\n",
        "df.eng=df.eng.apply(lambda x : '[go] ' + x + ' [stop]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz5J4wOMHhjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove extra spaces# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in df.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "# Vocabulary of Hindi \n",
        "all_hin_words=set()\n",
        "for hin in df.hin:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hin_words:\n",
        "            all_hin_words.add(word)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXuy5DGyKuk",
        "colab_type": "text"
      },
      "source": [
        "#### Finding maximum sentence length in English text Corpus and HIndi Text Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJxETuZ8Hl5J",
        "colab_type": "code",
        "outputId": "00d1a111-1877-431f-ab55-558121576328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Max Length of source[Hindi] sequence\n",
        "lenght_list=[]\n",
        "for l in df.hin:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "print(\"Maximum length of sentence in whole hindi Documents ::: {}\".format(max_length_src))\n",
        "\n",
        "# Max Length of target[English] sequence\n",
        "lenght_list=[]\n",
        "for l in df.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "print(\"Maximum length of sentence in whole English Documents ::: {}\".format(max_length_tar))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length of sentence in whole hindi Documents ::: 111\n",
            "Maximum length of sentence in whole English Documents ::: 136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "matJaI50yngd",
        "colab_type": "text"
      },
      "source": [
        "### Storing  unique words[tokens] in a varibles for  hindi corpus  and English corpus  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_t28v7tHrkG",
        "colab_type": "code",
        "outputId": "86045824-91da-400f-e4da-039b382ba7db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_words = sorted(list(all_hin_words))\n",
        "target_words = sorted(list(all_eng_words))\n",
        "num_encoder_tokens = len(all_hin_words)\n",
        "num_decoder_tokens = len(all_eng_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6290, 5615)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL2blybTH79X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_decoder_tokens += 1\n",
        "num_encoder_tokens += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYnmbopzm4r",
        "colab_type": "text"
      },
      "source": [
        "### convert unique tokens in form of (tokens,index) tuple\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ABflq22Ilfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtcbwy10ADa",
        "colab_type": "text"
      },
      "source": [
        "### convert unique tokens in form of (tokens,index) tuple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIsmVcKfInqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSw24VKSIpYN",
        "colab_type": "code",
        "outputId": "376cc3e9-20f0-403b-dd75-0ba73632ffd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "df = shuffle(df)\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hin</th>\n",
              "      <th>eng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34564</th>\n",
              "      <td>इस सीडी या डीवीडी डिस्क की कॉपी करें</td>\n",
              "      <td>[go] create a copy of this cd or dvd [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63746</th>\n",
              "      <td>वेब विकास</td>\n",
              "      <td>[go] web development [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16422</th>\n",
              "      <td>पूर्ण के साथ स्थिति कोड नहीं</td>\n",
              "      <td>[go] completed unsuccessfully with status code...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27585</th>\n",
              "      <td>औज़ार युक्ति</td>\n",
              "      <td>[go] tool tip [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92857</th>\n",
              "      <td>क्या आप निश्चित हैं कि आप प्रारूप में संदेश भे...</td>\n",
              "      <td>[go] are you sure you want to send a message i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61781</th>\n",
              "      <td>पसंद निर्यात करें</td>\n",
              "      <td>[go] export bookmarks [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16740</th>\n",
              "      <td>बिल्ड माड्यूल</td>\n",
              "      <td>[go] build module [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51279</th>\n",
              "      <td>वर्तनीजांच भाषा</td>\n",
              "      <td>[go] enable spell checking for languages [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43191</th>\n",
              "      <td>फ़ॉन्ट उपपिक्सल अनुक्रम</td>\n",
              "      <td>[go] font subpixel order [stop]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5059</th>\n",
              "      <td>को एक ईंट का इक्का पर ले जाएँ</td>\n",
              "      <td>[go] move a onto the ace of diamonds [stop]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     hin                                                eng\n",
              "34564               इस सीडी या डीवीडी डिस्क की कॉपी करें        [go] create a copy of this cd or dvd [stop]\n",
              "63746                                          वेब विकास                        [go] web development [stop]\n",
              "16422                       पूर्ण के साथ स्थिति कोड नहीं  [go] completed unsuccessfully with status code...\n",
              "27585                                       औज़ार युक्ति                               [go] tool tip [stop]\n",
              "92857  क्या आप निश्चित हैं कि आप प्रारूप में संदेश भे...  [go] are you sure you want to send a message i...\n",
              "61781                                  पसंद निर्यात करें                       [go] export bookmarks [stop]\n",
              "16740                                      बिल्ड माड्यूल                           [go] build module [stop]\n",
              "51279                                    वर्तनीजांच भाषा    [go] enable spell checking for languages [stop]\n",
              "43191                            फ़ॉन्ट उपपिक्सल अनुक्रम                    [go] font subpixel order [stop]\n",
              "5059                       को एक ईंट का इक्का पर ले जाएँ        [go] move a onto the ace of diamonds [stop]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxwjD3z20eWa",
        "colab_type": "text"
      },
      "source": [
        "## Explaning Encoder and Decoder Architecture\n",
        "* for encoder we can use any deeplearning models like (MLP,CNN,RNN,LSTM,GRU)\n",
        "* for decoder we also can use any deeplearning models like (MLP,CNN,RNN,LSTM,GRU)\n",
        "*  BUt for this word2word sequence problem for both  encoder and the decoder are typically use LSTM models (or sometimes GRU models)\n",
        "* Encoder Model :: \n",
        "  *  Encoder reads the input sequence and summarizes the information in something called as the internal state vectors (in case of LSTM these are called as the hidden state and cell state vectors). We discard the outputs of the encoder and only preserve the internal states.\n",
        "* Decoder MOdel ::\n",
        "  * Decoder is an LSTM whose initial states are initialized to the final states of the Encoder LSTM. Using these initial states, decoder starts generating the output sequence.\n",
        "  * The decoder behaves a bit differently during the training and inference procedure. During the training, we use a technique call teacher forcing which helps to train the decoder faster. During inference, the input to the decoder at each time step is the output from the previous time step.\n",
        "  \n",
        "* Final intutation :: \n",
        "  * Intuitively, the encoder summarizes the input sequence into state vectors (sometimes also called as Thought vectors), which are then fed to the decoder which starts generating the output sequence given the Thought vectors\n",
        "  * The decoder is just a language model conditioned on the initial states.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui0g4rr33_Z2",
        "colab_type": "text"
      },
      "source": [
        "### Specifing Traning and Testing Data\n",
        "* here for machine translation we have taken \n",
        "  * INPUT DATA as HIndi Sentence\n",
        "  * OUTPUT DATA as English Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ny634s0IXZ",
        "colab_type": "text"
      },
      "source": [
        "### Spliting  Data into Train and Text in ratio of 0.33"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVhfRVoIrJN",
        "colab_type": "code",
        "outputId": "460f323c-225b-4dd6-b58d-c58c3fb10528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Train - Test Split\n",
        "X, y = df.hin, df.eng\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59552,) (29332,)\n",
            "(59552,) (29332,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHpkIYCKEM_b",
        "colab_type": "code",
        "outputId": "675e904f-a7db-4887-c15c-a2449d2e7e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16866                                 [go] cvsroot [stop]\n",
              "52442    [go] play a sound when a contact logs out [stop]\n",
              "24738               [go] cvs remove file directory [stop]\n",
              "Name: eng, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIRKtowjIz7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            \n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    #print(word)\n",
        "                    #print(target_text.split())\n",
        "                    #print(t)\n",
        "                    #print(len(target_text.split()))\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        #print(\"going\")\n",
        "                        decoder_input_data[i, t] = str(target_token_index[word]) # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the \"[go]\" token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98D8EJfwI5c3",
        "colab_type": "text"
      },
      "source": [
        "# Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szV1iBU9JkWp",
        "colab_type": "text"
      },
      "source": [
        "#### Specifying Embedding output dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfWXNf5sI3Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdBfMPhQJvR0",
        "colab_type": "text"
      },
      "source": [
        "### Encoder LSTM Model \n",
        " 1. need to convert encoder input data into vectorization form .for that we are using Embedding Function\n",
        " 2. Embedding Function \n",
        "    * coverts each value into vector form\n",
        "    * for that we need to train  Embedding Model by specifying  input_dimension  , output_dimension with input_data\n",
        "    * input_dimension  = num_encoder_tokens\n",
        "    * output_dimension = latent_dim\n",
        "    * input_data       = Encoder_input_data\n",
        " 3. Specifying LSTM model \n",
        "    *  with units = 50\n",
        "    * return_state = True\n",
        " 4. Storing final states of Encoder_LSTM model in a varible  encoder_states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ao5PU6I9Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LJ38DgFMe-Q",
        "colab_type": "text"
      },
      "source": [
        "### Decoder LSTM Model \n",
        " 1. need to convert Decoder input data into vectorization form .for that we are using Embedding Function\n",
        " 2. Embedding Function \n",
        "    * coverts each value into vector form\n",
        "    * for that we need to train  Embedding Model by specifying  input_dimension  , output_dimension with input_data\n",
        "    * input_dimension  = num_decoder_tokens\n",
        "    * output_dimension = latent_dim\n",
        "    * input_data       = Encoder_input_data\n",
        " 3. Specifying LSTM model \n",
        "    *  with units = 50\n",
        "    * return_state = True\n",
        "    * return_sequences=True [ because we want to get full output sequence]\n",
        " 4.  For DecoderLTSM input Data is Final_States_of_Encoder and decoder_inputData\n",
        " 5.  Applying Softmax Function on top of DecoderOutput \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uysUKQfMI_RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using 'ncoder_states as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# encoder_input_data & decoder_input_data into decoder_target_data\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t4kPfryOxU-",
        "colab_type": "text"
      },
      "source": [
        "### model Compiling \n",
        "1. using lossFunction as 'categorical_crossentropy'\n",
        "1. we can use any of optimizaion algorithms like 'rmsprop','adm','Adadelta' etc\n",
        "2. metric have choose for this accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ggyYxRoJBXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gene-jfP51R",
        "colab_type": "text"
      },
      "source": [
        "#### Specifying len_training_Samples,len_validation_Samples,Batch_Size and Epochs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqo6wbdeJI3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoZxivLWQgtZ",
        "colab_type": "text"
      },
      "source": [
        "### Running Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vAfa0jVdJ1t",
        "colab_type": "code",
        "outputId": "f1947dc8-5e2a-427f-f510-e032320f9f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                            steps_per_epoch = train_samples//batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                            validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "465/465 [==============================] - 552s 1s/step - loss: 5.9172 - acc: 0.1816 - val_loss: 5.4882 - val_acc: 0.2059\n",
            "Epoch 2/20\n",
            "465/465 [==============================] - 541s 1s/step - loss: 5.2612 - acc: 0.2172 - val_loss: 5.0921 - val_acc: 0.2300\n",
            "Epoch 3/20\n",
            "465/465 [==============================] - 541s 1s/step - loss: 4.9225 - acc: 0.2432 - val_loss: 4.8106 - val_acc: 0.2571\n",
            "Epoch 4/20\n",
            "465/465 [==============================] - 539s 1s/step - loss: 4.6263 - acc: 0.2738 - val_loss: 4.5171 - val_acc: 0.2904\n",
            "Epoch 5/20\n",
            "465/465 [==============================] - 540s 1s/step - loss: 4.3305 - acc: 0.3087 - val_loss: 4.2571 - val_acc: 0.3224\n",
            "Epoch 6/20\n",
            "465/465 [==============================] - 540s 1s/step - loss: 4.0662 - acc: 0.3408 - val_loss: 4.0197 - val_acc: 0.3523\n",
            "Epoch 7/20\n",
            "465/465 [==============================] - 538s 1s/step - loss: 3.8284 - acc: 0.3723 - val_loss: 3.8067 - val_acc: 0.3803\n",
            "Epoch 8/20\n",
            "465/465 [==============================] - 539s 1s/step - loss: 3.6177 - acc: 0.4011 - val_loss: 3.6273 - val_acc: 0.4071\n",
            "Epoch 9/20\n",
            "465/465 [==============================] - 538s 1s/step - loss: 3.4308 - acc: 0.4279 - val_loss: 3.4693 - val_acc: 0.4302\n",
            "Epoch 10/20\n",
            "465/465 [==============================] - 537s 1s/step - loss: 3.2640 - acc: 0.4524 - val_loss: 3.3239 - val_acc: 0.4527\n",
            "Epoch 11/20\n",
            "465/465 [==============================] - 540s 1s/step - loss: 3.1064 - acc: 0.4766 - val_loss: 3.1907 - val_acc: 0.4721\n",
            "Epoch 12/20\n",
            "465/465 [==============================] - 541s 1s/step - loss: 2.9640 - acc: 0.4988 - val_loss: 3.0702 - val_acc: 0.4927\n",
            "Epoch 13/20\n",
            "465/465 [==============================] - 542s 1s/step - loss: 2.8345 - acc: 0.5195 - val_loss: 2.9652 - val_acc: 0.5084\n",
            "Epoch 14/20\n",
            "465/465 [==============================] - 543s 1s/step - loss: 2.7168 - acc: 0.5385 - val_loss: 2.8552 - val_acc: 0.5267\n",
            "Epoch 15/20\n",
            "465/465 [==============================] - 544s 1s/step - loss: 2.6107 - acc: 0.5561 - val_loss: 2.7702 - val_acc: 0.5404\n",
            "Epoch 16/20\n",
            "465/465 [==============================] - 544s 1s/step - loss: 2.5146 - acc: 0.5729 - val_loss: 2.6889 - val_acc: 0.5557\n",
            "Epoch 17/20\n",
            "465/465 [==============================] - 545s 1s/step - loss: 2.4280 - acc: 0.5877 - val_loss: 2.6179 - val_acc: 0.5666\n",
            "Epoch 18/20\n",
            "465/465 [==============================] - 545s 1s/step - loss: 2.3492 - acc: 0.6025 - val_loss: 2.5599 - val_acc: 0.5787\n",
            "Epoch 19/20\n",
            "465/465 [==============================] - 541s 1s/step - loss: 2.2756 - acc: 0.6159 - val_loss: 2.4964 - val_acc: 0.5908\n",
            "Epoch 20/20\n",
            "465/465 [==============================] - 544s 1s/step - loss: 2.2095 - acc: 0.6280 - val_loss: 2.4359 - val_acc: 0.6017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3381077be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCwDWQ4FQm3t",
        "colab_type": "text"
      },
      "source": [
        "### Saving weights of model in nwt_weights.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV4Q2yQbSzUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('nmt_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuoqo6UEPyvp",
        "colab_type": "code",
        "outputId": "9cf135b1-3fb4-4ce1-ad00-174ff28273f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  english.txt  hindi.txt  nmt_weights.h5  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwXH3IHiRfIc",
        "colab_type": "text"
      },
      "source": [
        "### Inference Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlOjrVRcLrJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I69HSm-P19t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['[go]']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '[stop]' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBRh9aqXSBHf",
        "colab_type": "text"
      },
      "source": [
        "#### Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkal9fNXP3xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrtrJqyTP708",
        "colab_type": "code",
        "outputId": "c87505aa-6a42-4b6c-dae3-9d2f8feda8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "k+=1\n",
        "print(k)\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "#print(input_seq)\n",
        "#print(actual_output)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print(decoded_sentence)\n",
        "print('Input Hindi sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual English Translation:', y_train[k:k+1].values[0][4:-6])\n",
        "\n",
        "print('Predicted English Translation:', decoded_sentence[:-6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            " complete log [stop]\n",
            "Input Hindi sentence: प्रतिशत समाप्तः र्ण\n",
            "Actual English Translation:  percent complete i \n",
            "Predicted English Translation:  complete log \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Se3quHLnT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}